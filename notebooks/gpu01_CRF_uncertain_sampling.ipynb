{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6024f606-7aa7-4f43-bc5b-4941a2686579",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8a1323-2a17-4814-8206-67e0cbe1d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07dade98-d203-4c37-9201-094d4fa9684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.lang.en import English\n",
    "from medspacy_io.reader.ehost_reader import EhostDocReader, EhostDirReader\n",
    "from spacy import displacy\n",
    "import medspacy\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from spacy.tokens import Doc\n",
    "from typing import List\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa1a12d-2026-4e98-b613-70482861d552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q:\\\\ORD_Bress_202112038D\\\\NLP\\\\notebooks_vb_exp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3074734-1e2a-4093-9e17-393710ab8ef9",
   "metadata": {},
   "source": [
    "## Read all the eHOST docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ead595b-6b3f-4164-a45a-a2824c58def4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyRuSH.PyRuSHSentencizer.PyRuSHSentencizer at 0x24918fc9180>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=English()\n",
    "nlp.add_pipe('medspacy_pyrush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd04508a-15e5-4c5d-b191-509ae92865ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ATTRIBUTES FROM SCHEMA: {'ANNOT_Worsening'}\n"
     ]
    }
   ],
   "source": [
    "merged_dir=r'..\\data\\merged_data1_8'\n",
    "dir_reader = EhostDirReader(nlp=nlp, recursive=False, use_adjudication=False,\n",
    "                            schema_file=str(Path(merged_dir, 'config', 'projectschema.xml')), support_overlap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762f6665-6fe5-4bc2-81dc-2dfff06abd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 15:10:59,441 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:10:59,444 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:10:59,446 root         WARNING  Attribute ANNOT_Temporality has not been set.\n",
      "2024-03-15 15:10:59,447 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:10:59,449 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:10:59,587 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:10:59,589 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:10:59,592 root         WARNING  Attribute ANNOT_Negation has not been set.\n",
      "2024-03-15 15:10:59,593 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:35,077 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:35,093 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:35,095 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,934 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,936 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,938 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,939 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,941 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,942 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,943 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,944 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,946 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,947 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,948 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,949 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,950 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:49,951 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:51,562 root         WARNING  Attribute ANNOT_Negation has not been set.\n",
      "2024-03-15 15:11:51,562 root         WARNING  Attribute ANNOT_Certainty has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Temporality has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Generic has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:11:51,577 root         WARNING  Attribute ANNOT_Subject has not been set.\n",
      "2024-03-15 15:12:11,303 root         WARNING  Attribute ANNOT_Subject has not been set.\n"
     ]
    }
   ],
   "source": [
    "docs=dir_reader.read(txt_dir=str(Path(merged_dir, 'corpus')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0461a366-fcb9-4ec6-9b22-90c14e3a127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d4283c4-d81c-4a90-a37f-3fd5b0658591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/merged_spacy_docs_1_8.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(docs, '../data/merged_spacy_docs_1_8.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae12c5-8860-438c-9e9c-daacf09aff74",
   "metadata": {},
   "source": [
    "## load pickled docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb63e5ca-fced-4991-8870-4c6de128ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=joblib.load('../data/merged_spacy_docs_1_8.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0f1e6-1515-4db9-af90-2b37f69bdd64",
   "metadata": {},
   "source": [
    "# Define sampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aedf902-836b-442b-89a4-5962d8d1495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds =10\n",
    "seed= 14\n",
    "train_total_docs, test_docs=train_test_split(docs, test_size=.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b9ce81-2d67-4b15-bca0-87af84c1dfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 255)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_total_docs), len(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c8a079f-5aa6-45c9-990a-1893eb7a7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spans_to_bio(doc:Doc, anno_types:List[str], abbr:bool=False)->str:\n",
    "  \"\"\"\n",
    "  Converts spans in a spaCy Doc object to a BIO-formatted string, with an option\n",
    "  to abbreviate the entity labels. It adds an empty line between sentences to improve\n",
    "  readability.\n",
    "\n",
    "  Parameters:\n",
    "  - doc (Doc): The spaCy Doc object containing the text and its annotations, including\n",
    "                entities and sentence boundaries.\n",
    "  - anno_types (List[str]): A list of annotation types to include in the output. These\n",
    "                            types should correspond to the keys in `doc.spans`.\n",
    "  - abbr (bool, optional): If True, entity labels are abbreviated to their initials.\n",
    "                            Defaults to True.\n",
    "\n",
    "  Returns:\n",
    "  - str: A string where each token is followed by its BIO tag (with the entity label if applicable),\n",
    "          formatted as \"token B-entity\" or \"token I-entity\" for tokens within entities, and\n",
    "          \"token O\" for tokens outside any entities. Sentences are separated by an empty line.\n",
    "  \"\"\"\n",
    "  # Initialize a dictionary to hold BIO tags for each token index\n",
    "  bio_tags = {token.i: 'O' for token in doc}  # Default to 'O' for outside any entity\n",
    "\n",
    "  # Preprocess spans to assign BIO tags\n",
    "  for anno_type, spans in doc.spans.items():\n",
    "    if anno_type not in anno_types:\n",
    "        continue\n",
    "    if len(spans)==0:\n",
    "        continue\n",
    "    for span in spans:\n",
    "        if span:  # Check if span is not empty\n",
    "          label=span.label_\n",
    "          if label not in anno_types:\n",
    "            continue\n",
    "          if abbr:\n",
    "            label=''.join([w[0] for w in label.split('_')])\n",
    "          bio_tags[span.start] = f\"B-{label}\"  # Begin tag for the first token in the span\n",
    "          for token in span[1:]:  # Inside tags for the rest of the tokens in the span\n",
    "            bio_tags[token.i] = f\"I-{label}\"\n",
    "\n",
    "  # Generate BIO format string\n",
    "  bio_text = []\n",
    "  bio_data={'sentence_id':[],'token':[],'label':[]}\n",
    "  for s,sent in enumerate(doc.sents):\n",
    "    for i,token in enumerate(sent):\n",
    "      # trim the whitespaces on both sides of a sentence\n",
    "      if (i==0 or i==len(sent)-1) and str(token).strip()=='':\n",
    "        bio_text.append('')\n",
    "        continue\n",
    "      elif str(token).strip()=='':\n",
    "        # clean up extra whitespaces within a sentence.\n",
    "        bio_text.append(f' \\t{bio_tags[token.i]}')\n",
    "        bio_data['label'].append(bio_tags[token.i])\n",
    "      else:\n",
    "        bio_text.append(f\"{token.text} {bio_tags[token.i]}\")\n",
    "        bio_data['label'].append(bio_tags[token.i])\n",
    "      bio_data['token'].append(token)\n",
    "      bio_data['sentence_id'].append(s)\n",
    "    bio_text.append('')  # Empty line between sentences\n",
    "  return '\\n'.join(bio_text), pd.DataFrame(bio_data)\n",
    "\n",
    "# We will focus on two types of concepts here\n",
    "def convert_docs(docs:List[Doc], anno_types=['FAM_COLON_CA','COLON_CA']):\n",
    "  all_conll=[]\n",
    "  offset=0\n",
    "  dfs=[]\n",
    "  for d in docs:\n",
    "    data, df=spans_to_bio(d, anno_types=anno_types)\n",
    "    all_conll.append(data)\n",
    "    df['sentence_id']+=offset\n",
    "    offset+=df.shape[0]\n",
    "    dfs.append(df)\n",
    "  return '\\n\\n'.join(all_conll), pd.concat(dfs)\n",
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    postag = word.pos_\n",
    "    word=str(word)\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        postag1 = word1.pos_\n",
    "        word1=str(word1)\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "        postag1 = word1.pos_\n",
    "        word1=str(word1)\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a48df27b-c9c8-4ea3-a32b-953274482ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_and_averages(y_true, y_pred):\n",
    "    def extract_entities(sentence_tags, row_id):\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        for i, tag in enumerate(sentence_tags):\n",
    "            if tag.startswith('B-'):\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = {'type': tag[2:], 'start': i, 'end': i, 'row_id': row_id}\n",
    "            elif tag.startswith('I-') and current_entity and current_entity['type'] == tag[2:]:\n",
    "                current_entity['end'] = i\n",
    "            else:\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "        if current_entity:\n",
    "            entities.append(current_entity)\n",
    "        return entities\n",
    "\n",
    "    # Initialize containers\n",
    "    metrics = {}\n",
    "    FP_ids = {}\n",
    "    FN_ids = {}\n",
    "\n",
    "    for row_id, (true_tags, pred_tags) in enumerate(zip(y_true, y_pred)):\n",
    "        true_entities = extract_entities(true_tags, row_id)\n",
    "        pred_entities = extract_entities(pred_tags, row_id)\n",
    "\n",
    "        for entity in true_entities + pred_entities:\n",
    "            entity_type = entity['type']\n",
    "            if entity_type not in metrics:\n",
    "                metrics[entity_type] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
    "                FP_ids[entity_type] = []\n",
    "                FN_ids[entity_type] = []\n",
    "\n",
    "        for pred_entity in pred_entities:\n",
    "            matched = False\n",
    "            for true_entity in true_entities:\n",
    "                if pred_entity['type'] == true_entity['type'] and not (pred_entity['end'] < true_entity['start'] or pred_entity['start'] > true_entity['end']):\n",
    "                    metrics[pred_entity['type']]['TP'] += 1\n",
    "                    matched = True\n",
    "                    true_entities.remove(true_entity)\n",
    "                    break\n",
    "            if not matched:\n",
    "                metrics[pred_entity['type']]['FP'] += 1\n",
    "                FP_ids[pred_entity['type']].append(pred_entity['row_id'])\n",
    "\n",
    "        for true_entity in true_entities:\n",
    "            metrics[true_entity['type']]['FN'] += 1\n",
    "            FN_ids[true_entity['type']].append(true_entity['row_id'])\n",
    "\n",
    "    # Calculate micro and macro averages\n",
    "    total_TP = sum(metrics[etype]['TP'] for etype in metrics)\n",
    "    total_FP = sum(metrics[etype]['FP'] for etype in metrics)\n",
    "    total_FN = sum(metrics[etype]['FN'] for etype in metrics)\n",
    "\n",
    "    micro_precision = total_TP / (total_TP + total_FP) if total_TP + total_FP > 0 else 0\n",
    "    micro_recall = total_TP / (total_TP + total_FN) if total_TP + total_FN > 0 else 0\n",
    "    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall) if micro_precision + micro_recall > 0 else 0\n",
    "\n",
    "    precisions = [metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FP']) if metrics[etype]['TP'] + metrics[etype]['FP'] > 0 else 0 for etype in metrics]\n",
    "    recalls = [metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FN']) if metrics[etype]['TP'] + metrics[etype]['FN'] > 0 else 0 for etype in metrics]\n",
    "    macro_precision = sum(precisions) / len(metrics) if metrics else 0\n",
    "    macro_recall = sum(recalls) / len(metrics) if metrics else 0\n",
    "    macro_f1 = 2 * macro_precision * macro_recall / (macro_precision + macro_recall) if macro_precision + macro_recall > 0 else 0\n",
    "\n",
    "    # Prepare DataFrame\n",
    "    data = {\n",
    "        'Entity Type': list(metrics.keys()) + ['Micro Average', 'Macro Average'],\n",
    "        'Precision': [metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FP']) if metrics[etype]['TP'] + metrics[etype]['FP'] > 0 else 0 for etype in metrics] + [micro_precision, macro_precision],\n",
    "        'Recall': [metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FN']) if metrics[etype]['TP'] + metrics[etype]['FN'] > 0 else 0 for etype in metrics] + [micro_recall, macro_recall],\n",
    "        'F1': [2 * (metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FP']) * metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FN'])) / ((metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FP'])) + (metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FN']))) if (metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FP'])) + (metrics[etype]['TP'] / (metrics[etype]['TP'] + metrics[etype]['FN'])) > 0 else 0 for etype in metrics] + [micro_f1, macro_f1]\n",
    "    }\n",
    "\n",
    "    results_df = pd.DataFrame(data)\n",
    "    return results_df, FP_ids, FN_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89180d-7331-4737-bfd7-626b66eae5f8",
   "metadata": {},
   "source": [
    "### Define CRF Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64c66e94-fc84-4943-bc6c-fc584406f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PsychDisorder', 'CFI', 'PsychHospitalization', 'Dementia', 'OtherCause', 'Intoxication', 'Delirium', 'Interference'}\n"
     ]
    }
   ],
   "source": [
    "## Get all annotation types: \n",
    "annos=set()\n",
    "for d in train_total_docs:\n",
    "    for anno in d.spans.keys():\n",
    "        annos.add(anno)\n",
    "annos.remove('PRE')   \n",
    "print(annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1a4e263-d7de-4eaf-b628-32c73a5eb3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFWrapper(object):\n",
    "    def __init__(self, anno_types=[]):\n",
    "        self.crf = sklearn_crfsuite.CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True)\n",
    "        self.anno_types=anno_types\n",
    "\n",
    "    def __df2features(self, df:pd.DataFrame):\n",
    "        X=[sent2features(list(sdf['token'])) for id,sdf in df.groupby('sentence_id')]\n",
    "        y=[list(sdf['label']) for id,sdf in df.groupby('sentence_id')]\n",
    "        return X,y\n",
    "        \n",
    "    def fit(self, docs: List[Doc]):\n",
    "        _, train_df=convert_docs(docs, anno_types=self.anno_types)\n",
    "        X_train, y_train=self.__df2features(train_df)\n",
    "        self.crf.fit(X_train, y_train)\n",
    "\n",
    "    def transform(self, docs:List[Doc], anno_types=[]):\n",
    "        _, test_df=convert_docs(docs, anno_types=self.anno_types)\n",
    "        X_test, y_test=self.__df2features(test_df)\n",
    "        y_pred = self.crf.predict(X_test)\n",
    "        return y_test, y_pred \n",
    "\n",
    "    def eval(self, docs:List[Doc]):\n",
    "        y_test, y_pred =self.transform(docs)\n",
    "        results_df, FP_ids, FN_ids=compute_metrics_and_averages(y_test, y_pred)\n",
    "        return results_df, FP_ids, FN_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "63f516b7-e565-4e70-905c-10e93bb704a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model=CRFWrapper(annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60dd7712-af35-42b2-87ce-b2457f9afe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model.fit(round0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f5f11b66-f105-4915-ae6e-1a916686369f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results_df, FP_ids, FN_ids\u001b[38;5;241m=\u001b[39m\u001b[43mcrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m results_df\n",
      "Cell \u001b[1;32mIn[87], line 29\u001b[0m, in \u001b[0;36mCRFWrapper.eval\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, docs:List[Doc]):\n\u001b[0;32m     28\u001b[0m     y_test, y_pred \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(docs)\n\u001b[1;32m---> 29\u001b[0m     results_df, FP_ids, FN_ids\u001b[38;5;241m=\u001b[39m\u001b[43mcompute_metrics_and_averages\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_df, FP_ids, FN_ids\n",
      "Cell \u001b[1;32mIn[41], line 72\u001b[0m, in \u001b[0;36mcompute_metrics_and_averages\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     65\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m macro_precision \u001b[38;5;241m*\u001b[39m macro_recall \u001b[38;5;241m/\u001b[39m (macro_precision \u001b[38;5;241m+\u001b[39m macro_recall) \u001b[38;5;28;01mif\u001b[39;00m macro_precision \u001b[38;5;241m+\u001b[39m macro_recall \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Prepare DataFrame\u001b[39;00m\n\u001b[0;32m     68\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntity Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro Average\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro Average\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: [metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m etype \u001b[38;5;129;01min\u001b[39;00m metrics] \u001b[38;5;241m+\u001b[39m [micro_precision, macro_precision],\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m: [metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m etype \u001b[38;5;129;01min\u001b[39;00m metrics] \u001b[38;5;241m+\u001b[39m [micro_recall, macro_recall],\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m/\u001b[39m ((metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m+\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m]))) \u001b[38;5;28;01mif\u001b[39;00m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m+\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m etype \u001b[38;5;129;01min\u001b[39;00m metrics] \u001b[38;5;241m+\u001b[39m [micro_f1, macro_f1]\n\u001b[0;32m     73\u001b[0m }\n\u001b[0;32m     75\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_df, FP_ids, FN_ids\n",
      "Cell \u001b[1;32mIn[41], line 72\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     65\u001b[0m macro_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m macro_precision \u001b[38;5;241m*\u001b[39m macro_recall \u001b[38;5;241m/\u001b[39m (macro_precision \u001b[38;5;241m+\u001b[39m macro_recall) \u001b[38;5;28;01mif\u001b[39;00m macro_precision \u001b[38;5;241m+\u001b[39m macro_recall \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Prepare DataFrame\u001b[39;00m\n\u001b[0;32m     68\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntity Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMicro Average\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacro Average\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: [metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m etype \u001b[38;5;129;01min\u001b[39;00m metrics] \u001b[38;5;241m+\u001b[39m [micro_precision, macro_precision],\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m: [metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m etype \u001b[38;5;129;01min\u001b[39;00m metrics] \u001b[38;5;241m+\u001b[39m [micro_recall, macro_recall],\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m/\u001b[39m ((metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m+\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m]))) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43metype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43metype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43metype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m metrics[etype][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFN\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m etype \u001b[38;5;129;01min\u001b[39;00m metrics] \u001b[38;5;241m+\u001b[39m [micro_f1, macro_f1]\n\u001b[0;32m     73\u001b[0m }\n\u001b[0;32m     75\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_df, FP_ids, FN_ids\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "results_df, FP_ids, FN_ids=crf_model.eval(test_docs)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6a6b9c3-194a-41dd-a8b2-08c956b48725",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_df=convert_docs(train_total_docs, anno_types=annos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9dac8842-71ad-4c22-b212-b2fd93161ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs=train_df[train_df['label']!='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0c9819e1-760b-4141-9158-51e5daa827f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5174</td>\n",
       "      <td>Overestimates</td>\n",
       "      <td>B-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5174</td>\n",
       "      <td>/</td>\n",
       "      <td>I-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5174</td>\n",
       "      <td>forgets</td>\n",
       "      <td>I-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>5174</td>\n",
       "      <td>limit[x]15</td>\n",
       "      <td>I-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>5211</td>\n",
       "      <td>dementia</td>\n",
       "      <td>B-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>413805</td>\n",
       "      <td>Alteration</td>\n",
       "      <td>B-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>413805</td>\n",
       "      <td>in</td>\n",
       "      <td>I-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>413805</td>\n",
       "      <td>mental</td>\n",
       "      <td>I-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>413805</td>\n",
       "      <td>status</td>\n",
       "      <td>I-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>413805</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>B-C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3061 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id          token label\n",
       "123          5174  Overestimates   B-C\n",
       "124          5174              /   I-C\n",
       "125          5174        forgets   I-C\n",
       "126          5174     limit[x]15   I-C\n",
       "492          5211       dementia   B-D\n",
       "...           ...            ...   ...\n",
       "1323       413805     Alteration   B-C\n",
       "1324       413805             in   I-C\n",
       "1325       413805         mental   I-C\n",
       "1326       413805         status   I-C\n",
       "1327       413805      Confusion   B-C\n",
       "\n",
       "[3061 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ae4fa4c-0546-491f-a97c-eef5a2303f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, FP_ids, FN_ids=crf_model.eval(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "39636110-4b1d-4a27-86f7-6b008f716e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.468293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.243243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.735849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Micro Average</td>\n",
       "      <td>0.644144</td>\n",
       "      <td>0.387534</td>\n",
       "      <td>0.483926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Macro Average</td>\n",
       "      <td>0.681232</td>\n",
       "      <td>0.412095</td>\n",
       "      <td>0.513538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entity Type  Precision    Recall        F1\n",
       "0              O   0.615385  0.377953  0.468293\n",
       "1              C   0.642857  0.305085  0.413793\n",
       "2              I   0.281250  0.214286  0.243243\n",
       "3              D   0.866667  0.639344  0.735849\n",
       "4              P   1.000000  0.523810  0.687500\n",
       "5  Micro Average   0.644144  0.387534  0.483926\n",
       "6  Macro Average   0.681232  0.412095  0.513538"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f4c5b-2841-4f06-b152-87d954dac967",
   "metadata": {},
   "source": [
    "### Define completely random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e91105bb-1ded-4948-a095-2e93ad12b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_sample(data, num=10, seed=14):\n",
    "    random.seed(seed)  \n",
    "    sampled_indices=random.sample(range(len(data)), num);\n",
    "    sampeld_sublist=[data[i] for i in sampled_indices]\n",
    "    sampled_indices=set(sampled_indices)\n",
    "    remaining_sublist = [d for i,d in enumerate(data) if i not in sampled_indices]\n",
    "    return sampeld_sublist, remaining_sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b48adecc-929f-4d47-866d-646ab0b2129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "round0, remain=rand_sample(train_total_docs, num=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7abc2e7a-235a-4370-88de-dcd7e69a67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model=CRFWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15094e4a-db02-402e-93f4-55eb467fdd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model.fit(round0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79ae32-66cc-4ac0-a2d2-0607490e61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_uncertainty_sampling(model, X_unlabeled, y_unlabeled, n_instances=1):\n",
    "    uncertainties = []\n",
    "    for xseq in X_unlabeled:\n",
    "        marginals = model.predict_marginals_single(xseq)\n",
    "        seq_uncertainty = np.mean([1 - max(token.values()) for token in marginals])\n",
    "        uncertainties.append(seq_uncertainty)\n",
    "    # Get indices of the n_instances most uncertain samples\n",
    "    selected_indices = np.argsort(uncertainties)[-n_instances:]\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2d21d-c41f-4398-a4eb-91df90ec5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the labeled and unlabeled pools\n",
    "initial_subset_size = len(data_df) // 10\n",
    "labeled_df = data_df.sample(n=initial_subset_size)\n",
    "unlabeled_df = data_df.drop(labeled_df.index)\n",
    "\n",
    "# For storing evaluation results\n",
    "f1_scores = []\n",
    "\n",
    "# Perform 10 iterations of sampling and training\n",
    "for i in range(1, 11):\n",
    "    print(f\"Iteration: {i}\")\n",
    "    \n",
    "    # Preprocess and train\n",
    "    train_sents = df_to_sentences(labeled_df)\n",
    "    X_train = sentences_to_features(train_sents)\n",
    "    y_train = sentences_to_labels(train_sents)\n",
    "    crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_sents = df_to_sentences(eval_df)\n",
    "    X_eval = sentences_to_features(eval_sents)\n",
    "    y_eval = sentences_to_labels(eval_sents)\n",
    "    y_pred = crf.predict(X_eval)\n",
    "    f1 = flat_f1_score(y_eval, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    if len(unlabeled_df) == 0:\n",
    "        break\n",
    "    \n",
    "    # Incrementally sample from the unlabeled pool\n",
    "    unlabeled_sents = df_to_sentences(unlabeled_df)\n",
    "    X_unlabeled = sentences_to_features(unlabeled_sents)\n",
    "    y_unlabeled_dummy = sentences_to_labels(unlabeled_sents)  # Placeholder, not used for sampling\n",
    "    selected_indices = incremental_uncertainty_sampling(crf, X_unlabeled, y_unlabeled_dummy, n_instances=initial_subset_size)\n",
    "    \n",
    "    # Update the labeled and unlabeled pools\n",
    "    selected_df = unlabeled_df.iloc[selected_indices]\n",
    "    labeled_df = pd.concat([labeled_df, selected_df])\n",
    "    unlabeled_df = unlabeled_df.drop(selected_df.index)\n",
    "\n",
    "# Plotting the F1 scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(f1_scores) + 1), f1_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Weighted F1 Score')\n",
    "plt.title('F1 Score over Iterations of Uncertainty Sampling')\n",
    "plt.xticks(range(1, len(f1_scores) + 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
